{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from turtle import up\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "def windowed_dataset(dataset: tf.data.Dataset, window_size=5, shift=1, stride=1):\n",
    "    if window_size == None or window_size <= 0:\n",
    "        return dataset\n",
    "\n",
    "    def sub_to_batch(t1, t2=None):\n",
    "        t1_batches = t1.batch(window_size, drop_remainder=True)\n",
    "\n",
    "        if t2 is not None:\n",
    "            t2_batches = t2.batch(window_size, drop_remainder=True)\n",
    "            return tf.data.Dataset.zip(t1_batches, t2_batches)\n",
    "        else:\n",
    "            return t1_batches\n",
    "\n",
    "    return dataset.window(window_size, shift=shift, stride=stride, drop_remainder=True).flat_map(sub_to_batch).batch(window_size, drop_remainder=True)\n",
    "    return windows  #.batch(window_size, drop_remainder=drop_remainder)\n",
    "\n",
    "\n",
    "def windowed_batch_dataframe(df: pd.DataFrame, window_size=4, batch_size=None):\n",
    "    df = df.copy()\n",
    "    if batch_size is not None and batch_size > 0:\n",
    "        dataset = windowed_dataset(tf.data.Dataset.from_tensor_slices(df.values), window_size).batch(batch_size=batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = windowed_dataset(tf.data.Dataset.from_tensor_slices(df.values), window_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def windowed_batch_dataset(ds: tf.data.Dataset, window_size=4, batch_size=None):\n",
    "\n",
    "    if batch_size is not None and batch_size > 0:\n",
    "        dataset = windowed_dataset(ds, window_size).batch(batch_size=batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = windowed_dataset(ds, window_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def convert_to_numpy(ds: tf.data.Dataset):\n",
    "    # 将 dataset 转换为 NumPy 数组\n",
    "    numpy_array = None\n",
    "    for data in ds.as_numpy_iterator():\n",
    "        # 确保数据是 NumPy 数组\n",
    "        data_np = np.array(data)\n",
    "\n",
    "        # 如果 numpy_array 还没有初始化，初始化它\n",
    "        if numpy_array is None:\n",
    "            numpy_array = data_np\n",
    "        else:\n",
    "            # # 确保数据的形状与 numpy_array 相同\n",
    "            # if data_np.shape[1:] != numpy_array.shape[1:]:\n",
    "            #     raise ValueError(\"All data items must have the same shape except for the first dimension.\")\n",
    "\n",
    "            # 垂直堆叠数据\n",
    "            numpy_array = np.vstack((numpy_array, data_np))\n",
    "\n",
    "    return numpy_array\n",
    "\n",
    "\n",
    "def get_shape(*args):\n",
    "    shapes = []\n",
    "    for arg in args:\n",
    "        shapes.append(arg.shape if arg is not None else None)\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b  label\n",
      "0  11  11      1\n",
      "1  12  12      0\n",
      "2  13  13      1\n",
      "3  14  14      0\n",
      "4  15  15      1\n",
      "5  16  16      0\n",
      "6  17  17      1\n",
      "7  18  18      0\n",
      "8  19  19      1\n",
      "9  20  20      0\n"
     ]
    }
   ],
   "source": [
    "rows = 10\n",
    "feature_cols = ['a', 'b']\n",
    "label_cols = ['label']\n",
    "columns = feature_cols + label_cols  #['a', 'b', 'c']\n",
    "cols = len(columns)\n",
    "data_x = np.array([[i+10 for c in np.arange(1, cols)] + [i % 2] for i in np.arange(1, rows + 1)])\n",
    "\n",
    "df = pd.DataFrame(data_x, columns=columns)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Tensor(\"args_0:0\", shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "win_size = 2\n",
    "batch_size = 0\n",
    "\n",
    "\n",
    "def splice(a, b):\n",
    "    print('---------')\n",
    "    print(a)\n",
    "    return (a, b)\n",
    "\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((df[feature_cols], df[label_cols]))\n",
    "x = windowed_batch_dataset(ds, win_size, batch_size).map(splice)\n",
    "\n",
    "for aa in x:\n",
    "    _ = 1\n",
    "# print('x1 ===')\n",
    "# print(y)\n",
    "# print('===')\n",
    "# print(y)\n",
    "\n",
    "# a, b = convert_to_numpy(x), convert_to_numpy(y)\n",
    "# print(get_shape(a))\n",
    "# print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
