{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from locale import Error\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from turtle import up\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "def windowed_dataset(dataset: tf.data.Dataset, window_size=5, shift=1, stride=2):\n",
    "    if window_size == None or window_size <= 0:\n",
    "        return dataset\n",
    "\n",
    "    def sub_to_batch(t1, t2=None):\n",
    "        t1_batches = t1.batch(window_size, drop_remainder=True)\n",
    "\n",
    "        if t2 is not None:\n",
    "            t2_batches = t2.batch(window_size, drop_remainder=True)\n",
    "            return tf.data.Dataset.zip((t1_batches, t2_batches))\n",
    "        else:\n",
    "            return t1_batches\n",
    "\n",
    "    def pick_batch(t1, t2: tf.Tensor | None):\n",
    "        #return (t1, t2)\n",
    "        if t2 is None:\n",
    "            return t1\n",
    "        else:\n",
    "\n",
    "            # 获取张量的维度信息\n",
    "            ndim = 0 if t2.ndim is None else t2.ndim\n",
    "\n",
    "            # 确保张量至少有二维\n",
    "            if ndim >= 2:\n",
    "                # 获取第二维的大小\n",
    "                second_dim_size = t2.shape[1] if ndim > 2 else t2.shape[0]\n",
    "                # 提取每个第二维元素的第一个数\n",
    "                # 如果张量是二维的，直接使用 tensor[:, 0]\n",
    "                # 如果张量大于二维，确保正确处理其他维度\n",
    "                if ndim > 2:\n",
    "                    first_elements = t2[0, ...]  # 使用...来保持其余维度不变\n",
    "                else:  # 对于二维张量\n",
    "                    first_elements = t2[0]\n",
    "\n",
    "                print(first_elements.shape)\n",
    "                return t1, first_elements\n",
    "            else:\n",
    "                msg = \"The tensor does not have at least two dimensions to extract elements from the second dimension.\"\n",
    "                print(msg)\n",
    "                Error(msg)\n",
    "\n",
    "    return dataset.window(window_size, shift=shift, stride=stride, drop_remainder=True).flat_map(sub_to_batch).map(pick_batch)\n",
    "    return windows  #.batch(window_size, drop_remainder=drop_remainder)\n",
    "\n",
    "\n",
    "# def windowed_batch_dataframe(df: pd.DataFrame, window_size=4, batch_size=None):\n",
    "#     df = df.copy()\n",
    "#     if batch_size is not None and batch_size > 0:\n",
    "#         dataset = windowed_dataset(tf.data.Dataset.from_tensor_slices(df.values), window_size).batch(batch_size=batch_size, drop_remainder=True)\n",
    "#     else:\n",
    "#         dataset = windowed_dataset(tf.data.Dataset.from_tensor_slices(df.values), window_size)\n",
    "#     return dataset\n",
    "\n",
    "\n",
    "def windowed_batch_dataset(ds: tf.data.Dataset, window_size=4, batch_size=None):\n",
    "\n",
    "    if batch_size is not None and batch_size > 0:\n",
    "        dataset = windowed_dataset(ds, window_size).batch(batch_size=batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = windowed_dataset(ds, window_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def convert_to_numpy(ds: tf.data.Dataset):\n",
    "    # 将 dataset 转换为 NumPy 数组\n",
    "    numpy_array = None\n",
    "    for data in ds.as_numpy_iterator():\n",
    "        # 确保数据是 NumPy 数组\n",
    "        data_np = np.array(data)\n",
    "\n",
    "        # 如果 numpy_array 还没有初始化，初始化它\n",
    "        if numpy_array is None:\n",
    "            numpy_array = data_np\n",
    "        else:\n",
    "            # # 确保数据的形状与 numpy_array 相同\n",
    "            # if data_np.shape[1:] != numpy_array.shape[1:]:\n",
    "            #     raise ValueError(\"All data items must have the same shape except for the first dimension.\")\n",
    "\n",
    "            # 垂直堆叠数据\n",
    "            numpy_array = np.vstack((numpy_array, data_np))\n",
    "\n",
    "    return numpy_array\n",
    "\n",
    "\n",
    "def get_shape(*args):\n",
    "    shapes = []\n",
    "    for arg in args:\n",
    "        shapes.append(arg.shape if arg is not None else None)\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a   b  label\n",
      "0   11  11      1\n",
      "1   12  12      2\n",
      "2   13  13      0\n",
      "3   14  14      1\n",
      "4   15  15      2\n",
      "5   16  16      0\n",
      "6   17  17      1\n",
      "7   18  18      2\n",
      "8   19  19      0\n",
      "9   20  20      1\n",
      "10  21  21      2\n",
      "11  22  22      0\n",
      "12  23  23      1\n",
      "13  24  24      2\n",
      "14  25  25      0\n",
      "15  26  26      1\n",
      "16  27  27      2\n",
      "17  28  28      0\n",
      "18  29  29      1\n",
      "19  30  30      2\n"
     ]
    }
   ],
   "source": [
    "rows = 20\n",
    "class_num=3\n",
    "feature_cols = ['a', 'b']\n",
    "label_cols = ['label']\n",
    "columns = feature_cols + label_cols  #['a', 'b', 'c']\n",
    "cols = len(columns)\n",
    "data_x = np.array([[i + 10 for c in np.arange(1, cols)] + [i % class_num] for i in np.arange(1, rows + 1)])\n",
    "\n",
    "df = pd.DataFrame(data_x, columns=columns)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "************\n",
      "\n",
      "x--\n",
      "(3, 4, 2)\n",
      "y ==\n",
      "tf.Tensor([2 0 1], shape=(3,), dtype=int64)\n",
      "\n",
      "\n",
      "************\n",
      "\n",
      "x--\n",
      "(3, 4, 2)\n",
      "y ==\n",
      "tf.Tensor([2 0 1], shape=(3,), dtype=int64)\n",
      "\n",
      "\n",
      "************\n",
      "\n",
      "x--\n",
      "(3, 4, 2)\n",
      "y ==\n",
      "tf.Tensor([2 0 1], shape=(3,), dtype=int64)\n",
      "\n",
      "\n",
      "************\n",
      "\n",
      "x--\n",
      "(3, 4, 2)\n",
      "y ==\n",
      "tf.Tensor([2 0 1], shape=(3,), dtype=int64)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "win_size = 4\n",
    "batch_size = 3\n",
    "\n",
    "\n",
    "def splice(a, b):\n",
    "    print('---------')\n",
    "    print(a)\n",
    "    return (a, b)\n",
    "\n",
    "\n",
    "def one_hot_encoding(label):\n",
    "    # return label\n",
    "    return tf.squeeze(tf.one_hot(label, depth=class_num))\n",
    "\n",
    "\n",
    "ds_x = tf.data.Dataset.from_tensor_slices((df[feature_cols]))\n",
    "ds_y = tf.data.Dataset.from_tensor_slices((df[label_cols])).map(one_hot_encoding)\n",
    "# ds = tf.data.Dataset.from_tensor_slices((df[feature_cols], df[label_cols]))\n",
    "ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "win_ds = windowed_batch_dataset(ds, win_size, batch_size)  #.map(splice)\n",
    "for x, y in win_ds:\n",
    "    _ = 1\n",
    "for x, y in win_ds:\n",
    "    print('************')\n",
    "    print('')\n",
    "    print('x--')\n",
    "    # print(x)\n",
    "    print(x.shape)\n",
    "    print('y ==')\n",
    "    print(tf.argmax(y))\n",
    "    print('')\n",
    "    print('')\n",
    "# print('x1 ===')\n",
    "# print(y)\n",
    "# print('===')\n",
    "# print(y)\n",
    "\n",
    "# a, b = convert_to_numpy(x), convert_to_numpy(y)\n",
    "# print(get_shape(a))\n",
    "# print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311tf216",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
