{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab9684b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import datetime\n",
    "import matplotlib\n",
    "import itertools\n",
    "matplotlib.use(\"Agg\")  #这个设置可以使matplotlib保存.png图到磁盘\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94424e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter 中开启该选项，否则不执行\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6b675",
   "metadata": {},
   "source": [
    "配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "64575bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs=5\n",
    "regularizer=1e-3\n",
    "total_train_samples=60000\n",
    "total_test_samples=10000\n",
    "lr_decay_epochs=1\n",
    "output_folder=\"./model_output\"\n",
    "#用来保存模型以及我们需要的所有东西\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "save_format=\"hdf5\" #或saved_model\n",
    "if save_format==\"hdf5\":\n",
    "    save_path_models=os.path.join(output_folder,\"hdf5_models\")\n",
    "    if not os.path.exists(save_path_models):\n",
    "        os.makedirs(save_path_models)\n",
    "    model_save_path=os.path.join(save_path_models,\"ckpt_epoch{epoch:02d}_val_acc{val_accuracy:.2f}.hdf5\")\n",
    "    \n",
    "elif save_format==\"saved_model\":\n",
    "    save_path_models=os.path.join(output_folder,\"saved_models\")\n",
    "    if not os.path.exists(save_path_models):\n",
    "        os.makedirs(save_path_models)\n",
    "    model_save_path=os.path.join(save_path_models,\"ckpt_epoch{epoch:02d}_val_acc{val_accuracy:.2f}.ckpt\")\n",
    "#用来保存日志\n",
    "log_dir= os.path.join(output_folder,'logs_{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5889aa",
   "metadata": {},
   "source": [
    "选择指定显卡及自动调用显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "086d8cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the available GPUs:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')#列出所有可见显卡\n",
    "print(\"All the available GPUs:\\n\",physical_devices)\n",
    "if physical_devices:\n",
    "    gpu=physical_devices[0]#显示第一块显卡\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)#根据需要自动增长显存\n",
    "    tf.config.experimental.set_visible_devices(gpu, 'GPU')#只选择第一块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974d390",
   "metadata": {},
   "source": [
    "准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac14c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(train_x,train_y),(test_x,test_y)=fashion_mnist.load_data()\n",
    "\n",
    "train_x,test_x = train_x[...,np.newaxis]/255.0,test_x[...,np.newaxis]/255.0\n",
    "total_train_sample = train_x.shape[0]\n",
    "total_test_sample=test_x.shape[0]\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8440ae2",
   "metadata": {},
   "source": [
    "使用tf.data来准备训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6a9571f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x,test_y))\n",
    " \n",
    "train_ds=train_ds.shuffle(buffer_size=batch_size*10).batch(batch_size).prefetch(buffer_size = tf.data.experimental.AUTOTUNE).repeat()\n",
    "test_ds = test_ds.batch(batch_size).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)#不加repeat，执行一次就行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afeeb5c",
   "metadata": {},
   "source": [
    "准备模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d15b4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = keras.regularizers.l2(regularizer)#定义模型正则化方法\n",
    "ini = keras.initializers.he_normal()#定义参数初始化方法\n",
    "conv2d = partial(keras.layers.Conv2D,activation='relu',padding='same',kernel_regularizer=l2,bias_regularizer=l2)\n",
    "fc = partial(keras.layers.Dense,activation='relu',kernel_regularizer=l2,bias_regularizer=l2)\n",
    "maxpool=keras.layers.MaxPooling2D\n",
    "dropout=keras.layers.Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a2745a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = keras.layers.Input(shape=(28,28,1),name='input_node')\n",
    "x = conv2d(128,(5,5))(x_input)\n",
    "x = maxpool((2,2))(x)\n",
    "x = conv2d(256,(5,5))(x)\n",
    "x = maxpool((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = fc(128)(x)\n",
    "x_output=fc(10,activation=None,name='output_node')(x)\n",
    "model = keras.models.Model(inputs=x_input,outputs=x_output)                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7d735",
   "metadata": {},
   "source": [
    "打印模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "200a6c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architure:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_node (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_node (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_node (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m3,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m819,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_node (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,429,834</span> (9.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,429,834\u001b[0m (9.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,429,834</span> (9.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,429,834\u001b[0m (9.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"The model architure:\\n\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66820502",
   "metadata": {},
   "source": [
    "画出模型结构图并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aafd29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model,to_file=os.path.join(log_dir,'model.png'),show_shapes=True,show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7522e6",
   "metadata": {},
   "source": [
    "定义优化算法和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25881035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习率变化设置，使用指数衰减\n",
    "train_steps_per_epoch=int(total_train_samples//batch_size)\n",
    "initial_learning_rate=0.01\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "#                                                              decay_steps=1*train_steps_per_epoch,\n",
    "#                                                             decay_rate=0.96,\n",
    "#                                                             staircase=True)#initial_learning_rate*0.96**(step/decay_steps)\n",
    "#优化算法\n",
    "optimizer = keras.optimizers.SGD(learning_rate=initial_learning_rate,momentum=0.95)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.95)\n",
    "#损失函数\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#评价指标\n",
    "# metrics=[keras.metrics.SparseCategoricalAccuracy(),loss]\n",
    "metrics=['accuracy','sparse_categorical_crossentropy']\n",
    "#上式第二个参数会返回交叉熵的结果，用loss减去该值就会得到正则化的值（于model.losses和相等），这两种定义方式都可以，下边的会显示名称短一些\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5eaf1f",
   "metadata": {},
   "source": [
    "编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d8bac623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f75fa",
   "metadata": {},
   "source": [
    "# 定义callbacks\n",
    "1、生成ckpt每个epoch训练完保存一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "db0bee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存格式默认是saved_model,可以自己定义更改原有类来保存hdf5\n",
    "ckpt = keras.callbacks.ModelCheckpoint(model_save_path.replace('.hdf5', '.keras'), monitor='val_accuracy', verbose=1, save_best_only=False, save_weights_only=False, save_freq='epoch', mode='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733e875",
   "metadata": {},
   "source": [
    "monitor可选的内容与model.fit history的keys相同，如“loss\",“val_accuracy”,“val_loss”,使用这前可以查看一下有那些；save_best_only的True或False作用显然；save_weights_only的True或False指是否只保存模型参数；verbose=1时会打印日志；另外save_path有两种格式，h5或saved model,如save_path='model.h5’将自动保存h5模型（无论save_weights_only是True还是False),save_path=‘model’,将自动保存savedmodel,这时save_weights_only是True或False情况下格式略有不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0513ee3",
   "metadata": {},
   "source": [
    "2、当模型验证集精度长时间不再提升时停止训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "afcc6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#当模型训练不符合我们要求时停止训练，连续5个epoch验证集精度没有提高0.001%停\n",
    "earlystop=keras.callbacks.EarlyStopping(monitor='val_accuracy',min_delta = 0.0001,patience=5,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f262fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、自定义学习率按需衰减，并把整个学习率变化过程保存\n",
    "class LearningRateExponentialDecay:\n",
    "\n",
    "    def __init__(self, initial_learning_rate, decay_epochs, decay_rate):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        dtype = type(self.initial_learning_rate)\n",
    "        decay_epochs = np.array(self.decay_epochs).astype(dtype)\n",
    "        decay_rate = np.array(self.decay_rate).astype(dtype)\n",
    "        epoch = np.array(epoch).astype(dtype)\n",
    "        p = epoch / decay_epochs\n",
    "        lr = self.initial_learning_rate * np.power(decay_rate, p)\n",
    "        return lr\n",
    "\n",
    "\n",
    "lr_schedule = LearningRateExponentialDecay(initial_learning_rate, lr_decay_epochs, 0.96)\n",
    "lr = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "#使用tensorboard\n",
    "#定义当loss出现nan或inf时停止训练的callback\n",
    "terminate = keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "#模型损失长时间不除时大程度降低学习率\n",
    "# 这个策略通常不于学习率衰减schedule同时使用，或者使用时要合理\n",
    "#降低学习率（要比学习率自动周期变化有更大变化和更长时间监控）\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                              factor=0.1,\n",
    "                                              patience=3,\n",
    "                                              verbose=1,\n",
    "                                              min_delta=0.0001,\n",
    "                                              min_lr=0)\n",
    "# 模型损失长时间不除时大程度降低学习率\n",
    "# 这个策略通常不于学习率衰减schedule同时使用，或者使用时要合理\n",
    "\n",
    "#降低学习率（要比学习率自动周期变化有更大变化和更长时间监控）\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                              factor=0.1,\n",
    "                                              patience=3,\n",
    "                                              verbose=1,\n",
    "                                              min_delta=0.0001,\n",
    "                                              min_lr=0)\n",
    "#保存训练过程中大数标量指标，与tensorboard同一个文件\n",
    "csv_logger = keras.callbacks.CSVLogger(os.path.join(log_dir, 'logs.log'), separator=',')\n",
    "\n",
    "#还要加入tensorboard的使用,这种方法记录的内容有限\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,  #对参数和激活做直方图，一定要有测试集\n",
    "    write_graph=True,  #模型结构图\n",
    "    write_images=True,  #把模型参数做为图片形式存到\n",
    "    update_freq='epoch',  #epoch,batch,整数，太频的话会减慢速度\n",
    "    profile_batch=2,  #记录模型性能\n",
    "    embeddings_freq=1,\n",
    "    embeddings_metadata=None  #这个还不太清楚如何使用\n",
    ")\n",
    "#各个参数的作用请参看文档，需要正确使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49e3f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import io\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir, filename_suffix='cm')\n",
    "\n",
    "\n",
    "def plot_to_image(figure, logd_ir, epoch):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    fig = figure\n",
    "    fig.savefig(os.path.join(log_dir, 'during_train_confusion_epoch_{}.png'.format(epoch)))\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold[i] else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(test_x)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(test_y, test_pred)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure, log_dir, epoch)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5ca6d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8754 - loss: 0.5998 - sparse_categorical_crossentropy: 1.2982\n",
      "Epoch 1: saving model to ./model_output\\hdf5_models\\ckpt_epoch01_val_acc0.88.keras\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 284ms/step - accuracy: 0.8754 - loss: 0.5998 - sparse_categorical_crossentropy: 1.2981 - val_accuracy: 0.8815 - val_loss: 0.5146 - val_sparse_categorical_crossentropy: 1.2672 - learning_rate: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0096.\n",
      "Epoch 2/5\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.8915 - loss: 0.4708 - sparse_categorical_crossentropy: 1.2244\n",
      "Epoch 2: saving model to ./model_output\\hdf5_models\\ckpt_epoch02_val_acc0.00.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 257ms/step - accuracy: 0.8915 - loss: 0.4708 - sparse_categorical_crossentropy: 1.2244 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_sparse_categorical_crossentropy: 0.0000e+00 - learning_rate: 0.0096\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009216.\n",
      "Epoch 3/5\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9004 - loss: 0.4109 - sparse_categorical_crossentropy: 1.1877\n",
      "Epoch 3: saving model to ./model_output\\hdf5_models\\ckpt_epoch03_val_acc0.89.keras\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 270ms/step - accuracy: 0.9004 - loss: 0.4109 - sparse_categorical_crossentropy: 1.1877 - val_accuracy: 0.8939 - val_loss: 0.4308 - val_sparse_categorical_crossentropy: 1.1488 - learning_rate: 0.0092\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
      "Epoch 4/5\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9042 - loss: 0.3859 - sparse_categorical_crossentropy: 1.1492\n",
      "Epoch 4: saving model to ./model_output\\hdf5_models\\ckpt_epoch04_val_acc0.00.keras\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 266ms/step - accuracy: 0.9042 - loss: 0.3859 - sparse_categorical_crossentropy: 1.1492 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_sparse_categorical_crossentropy: 0.0000e+00 - learning_rate: 0.0088\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
      "Epoch 5/5\n",
      "\u001b[1m464/937\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 256ms/step - accuracy: 0.9108 - loss: 0.3628 - sparse_categorical_crossentropy: 1.1320"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m train_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(total_train_samples \u001b[38;5;241m/\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m      4\u001b[0m test_steps_per_epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(total_test_sample \u001b[38;5;241m/\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m----> 5\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#使用tf.data无法获取训练和测试总数，所以指定训练步数合使训练稳定\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\ScriptsApplications\\.devhome\\conda\\envs\\py311tf2.16\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [ckpt, earlystop, lr, tensorboard, terminate, reduce_lr, csv_logger]  #, cm_callback\n",
    "# H=model.fit(train_ds,epochs=epochs,steps_per_epoch=len(train_x)//batch_size,validation_data=test_ds)\n",
    "train_steps_per_epoch = np.floor(total_train_samples / batch_size).astype(np.int32)\n",
    "test_steps_per_epoch = np.ceil(total_test_sample / batch_size).astype(np.int32)\n",
    "H = model.fit(train_ds,\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=train_steps_per_epoch,\n",
    "              validation_data=test_ds,\n",
    "              validation_steps=test_steps_per_epoch,\n",
    "              callbacks=callbacks,\n",
    "              verbose=1)\n",
    "#使用tf.data无法获取训练和测试总数，所以指定训练步数合使训练稳定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739be32d",
   "metadata": {},
   "source": [
    "开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed312f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H=model.fit(train_ds,epochs=epochs,steps_per_epoch=len(train_x)//batch_size,validation_data=test_ds)\n",
    "train_steps_per_epoch=np.floor(total_train_samples/batch_size).astype(np.int32)\n",
    "test_steps_per_epoch = np.ceil(total_test_sample/batch_size).astype(np.int32)\n",
    "H=model.fit(train_ds,epochs=epochs,\n",
    "            steps_per_epoch=train_steps_per_epoch,\n",
    "            validation_data=test_ds,\n",
    "            validation_steps=test_steps_per_epoch,\n",
    "            callbacks=callbacks,verbose=1)\n",
    "#使用tf.data无法获取训练和测试总数，所以指定训练步数合使训练稳定\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#画学习率变化曲线并保存到log中\n",
    "def plot(lrs,title=\"Learning Rate Schedule\"):\n",
    "    #计算学习率随epoch的变化值\n",
    "    epochs=np.arange(len(lrs))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs,lrs)\n",
    "    plt.xticks(epochs)\n",
    "    plt.scatter(epochs,lrs)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "plot(H.history['lr'])\n",
    "plt.savefig(os.path.join(log_dir,'learning_rate.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a2f6e6",
   "metadata": {},
   "source": [
    "画模型训练及验证loss和acc曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = H.epochs\n",
    "plt.figure()\n",
    "plt.plot(N, H.history['loss'], label='train_loss')\n",
    "plt.scatter(N, H.history['loss'])\n",
    "plt.plot(N, H.history['val_loss'], label='val_loss')\n",
    "plt.scatter(N, H.history['val_loss'])\n",
    "plt.plot(N, H.history['accuracy'], label='train_acc')\n",
    "plt.scatter(N, H.history['accuracy'])\n",
    "plt.plot(N, H.history['val_accuracy'], label='val_acc')\n",
    "plt.scatter(N, H.history['val_accuracy'])\n",
    "plt.title('Training Loss and Accuracy on Our_dataset')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(log_dir, 'training.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde838f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型结构及配置参数\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(log_dir,'model_json.json'),'w') as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f29300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对模型在测试集上进行评估\n",
    "metrics=model.evaluate(test_ds,verbose=1)\n",
    "print(\"val_loss:\",metrics[0],\"val_accuracy:\",metrics[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_ds,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(labels, predictions,target_names,save=False,save_path=None):\n",
    "    # 计算confusion result\n",
    "    preds=np.argmax(predictions,axis=-1)\n",
    "    confusion_result = confusion_matrix(labels, preds)\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1500)\n",
    "    confusion_result = pd.DataFrame(confusion_result, index = target_names, columns = target_names)\n",
    "    # classification report\n",
    "    report = classification_report(labels, preds, target_names = target_names, digits = 4)\n",
    "    result_report = 'Confuse_matrix:\\n{}\\n\\nClassification_report:\\n{} \\n'.format(confusion_result, report)\n",
    "    print(result_report)\n",
    "    if save:   \n",
    "\n",
    "        savepath = os.path.join(save_path,\"predicted_result.txt\")\n",
    "\n",
    "        print('the result saved in %s' % savepath)#如果savepath相同的话,会把所有结果保存到同一个文件中\n",
    "\n",
    "        with open(savepath, 'w') as f:\n",
    "            f.write(result_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06aea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(test_y,predictions,class_names,True,log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13068dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree model_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311tf2.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
