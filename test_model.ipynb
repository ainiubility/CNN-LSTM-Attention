{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m attention_layer \u001b[38;5;241m=\u001b[39m Attention()([queries, values])\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# 时间分布的全连接层\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m time_distributed_layer \u001b[38;5;241m=\u001b[39m TimeDistributed(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))(\u001b[43mx\u001b[49m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 全连接层，用于分类\u001b[39;00m\n\u001b[0;32m     60\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Dense(units\u001b[38;5;241m=\u001b[39mnum_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(time_distributed_layer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input, Lambda, Conv3D, Bidirectional, LSTM, Dense, TimeDistributed, Attention, Reshape,Conv1D\n",
    "\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = inputs\n",
    "    #a = Permute((2, 1))(inputs)\n",
    "    #a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(input_dim, activation='softmax')(a)\n",
    "    \n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: keras.ops.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = layers.RepeatVector(input_dim)(a)\n",
    "    a_probs = layers.Permute((1, 2), name='attention_vec')(a)\n",
    "\n",
    "    #output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    output_attention_mul = layers.Multiply()([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "# 假设有1000个样本，每个样本有6个特征，时间步长为10\n",
    "timesteps = 10\n",
    "features = 6\n",
    "num_classes = 3\n",
    "\n",
    "# 生成随机数据\n",
    "data = np.random.rand(1000, timesteps, features)\n",
    "labels = np.random.randint(0, num_classes, (1000,))\n",
    "\n",
    "# 一热编码标签\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes)\n",
    "\n",
    "# 定义输入\n",
    "input_layer = Input(shape=(timesteps, features))\n",
    "\n",
    "# 3D卷积层\n",
    "conv1d_layer = Conv1D(filters=64, kernel_size=(3), activation='relu')(input_layer)\n",
    "\n",
    "v = layers.MaxPool1D(pool_size=2)(conv1d_layer)\n",
    "# BiLSTM层\n",
    "bilstm_output = Bidirectional(LSTM(units=64, return_sequences=True, return_state=False))(v)\n",
    "\n",
    "query_dim =features\n",
    "# 假设你的模型不需要键（key），只需要查询（query）和值（value）\n",
    "# 你可以简单地将 LSTM 层的输出分成两半\n",
    "queries = bilstm_output[:, :, :query_dim]\n",
    "values = bilstm_output[:, :, query_dim:]\n",
    "# 注意力层\n",
    "attention_layer = Attention()([queries, values])\n",
    "\n",
    "# 时间分布的全连接层\n",
    "time_distributed_layer = TimeDistributed(Dense(units=64, activation='relu'))(x)\n",
    "\n",
    "# 全连接层，用于分类\n",
    "output_layer = Dense(units=num_classes, activation='softmax')(time_distributed_layer)\n",
    "\n",
    "# 创建模型\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 打印模型概要\n",
    "model.summary()\n",
    "\n",
    "# 查看模型结构\n",
    "model.get_config()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311tf2.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
