{"cells":[{"metadata":{"solution":"hidden","id":"47E84156D613448D98B3310128DDDA1D","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"# 【快速上手】用ModelWhale做机器学习\n欢迎来到 ModelWhale  o(*￣▽￣*)ブ\n小鲸整理了GitHub开源项目，选取了一些问题场景，抽象出一个典型的工作流程为你讲解如何用ModelWhale进行机器学习。\n* 你可以点击【一键运行】在线运行这个项目，熟悉机器学习流程的同时[了解ModelWhale的用法](https://www.heywhale.com/docs/community/?from=quickstart2)\n* 如果代码基础较薄弱，你可以先去瞅瞅  [从零上手Python关键代码](https://www.heywhale.com/mw/project/59e4331c4663f7655c499bc3?from=quickstart2) 和 [Pandas基础命令速查表](https://www.heywhale.com/mw/project/59e389b54663f7655c48f518?from=quickstart2) \n* 如果想学习更多内容，戳[这里](https://www.heywhale.com/mw/project/5e72e367c59d610036225bc0?from=quickstart2)有完整路径哟~"},{"metadata":{"id":"121DFAF40B27432491FC8E33C8531BD7","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"# 目录\n* [线性回归问题](#线性回归问题)    \n* [分类问题](#分类问题)  "},{"metadata":{"id":"B2E794F6FDA5467FB26A58CDB990A902","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"# 线性回归问题\n\n1. [介绍](#1.介绍)\n * [1.1工作流程](#1.1工作流程)\n * [1.2目标任务](#1.2目标任务)\n2. [处理数据](#2.处理数据)\n3. [描述性统计&可视化](#3.描述性统计&可视化)\n4. [线性回归](#4.线性回归)\n * [4.1线性回归公式](#4.1线性回归公式) \n * [4.2用pandas预处理X和y](#4.2用pandas预处理X和y)\n * [4.3将数据集拆分成训练子集X和测试子集y](#4.3将数据集拆分成训练子集X和测试子集y)\n * [4.4在scikit-learn中使用线性回归](#4.4在scikit-learn中使用线性回归)\n * [4.5推断模型的相关系数](#4.5推断模型的相关系数)\n * [4.6做预测](#4.6做预测)\n * [4.7回归模型的评价指标](#4.7回归模型的评价指标)    \n * [4.8特征选择](#4.8特征选择)\n5. [参考资料](#5.参考资料)"},{"metadata":{"solution":"hidden","solution_first":true,"id":"226E4961FE7F400D9C05FB1EC88D30FA","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 1.介绍   \n### 1.1工作流程\n\n* 处理数据(pandas)\n* 描述性统计&可视化(seaborn)\n* 建立模型(scikit-learn)\n### 1.2目标任务\n\n- 如何用 ```pandas``` 读取数据？\n- 如何用 ```seaborn``` 做数据可视化？\n- 什么是线性回归，它是如何工作的？\n- 如何在```scikit-learn```中训练并解释一个线性回归模型(linear regression model)？\n- 衡量回归问题的指标有哪些？\n- 如何选择模型中的特征？    \n\n[返回问题](#线性回归问题)"},{"metadata":{"id":"71AD6AF1D1684A17BFF754A58472644C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 2.处理数据\n这一部分主要是讲述如何用pandas对数据进行处理，pandas一个流行的可以探索、处理并分析数据的Python工具包"},{"metadata":{"collapsed":false,"id":"353972DED2D74441A4885B99E84D9ACA","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 查看数据挂载的路径\n!ls ../input/mwstart","execution_count":4,"outputs":[]},{"metadata":{"collapsed":false,"id":"C8C73E216E1B47829E026305F72344C5","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 导入工具包\nimport pandas as pd","execution_count":5,"outputs":[]},{"metadata":{"collapsed":false,"id":"C2F72F9ED6A143B383F6CD32A89F9182","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 直接从URL中读取数据，当然也可以指定一个位置读取\ndata = pd.read_csv('../input/mwstart/Advertising.csv', index_col=0)","execution_count":6,"outputs":[]},{"metadata":{"collapsed":false,"id":"835860120C8F4F279D86D3A135459538","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 展示前五行\ndata.head()","execution_count":7,"outputs":[]},{"metadata":{"id":"CD4156BD0F4447F89FC38848740948A2","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"主要的对象类型:\n\n- **数据框(DataFrame):** 行与列的集合，类似表格。\n- **数组(Series):** 一个单独的列"},{"metadata":{"collapsed":false,"id":"9CF88E405C6D4FE7B4CF1E646A9CD753","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 显示最末尾五行\ndata.tail()","execution_count":8,"outputs":[]},{"metadata":{"collapsed":false,"id":"A22126E7668D4B13BFDB1CED880BA365","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 检查数据框的形状\ndata.shape","execution_count":9,"outputs":[]},{"metadata":{"id":"2D73B285D1E948C28DE3EE3D84DC048B","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"这些特征(feature)是什么?\n- **TV**: 每件产品在一个给定市场上的广告支出\n- **radio**: 花在radio上的广告支出\n- **newspaper**:花在newspaper上的广告支出\n\n响应值(response)是什么?\n- **sales:** 产品对应的销售额\n\n我们还知道什么？\n- 因为对应变量是连续的，这是一个**回归问题**\n- 有200个观察值，每个观察值对应一个单独的市场       \n\n[返回问题](#线性回归问题)"},{"metadata":{"id":"36D0CA0E732941A2B224964E39CC009A","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 3.描述性统计&可视化"},{"metadata":{"collapsed":false,"id":"E630B3FFA65C4C7B8D57753437207CF3","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n# 导入seaborn工具包\nimport seaborn as sns\n# 设置命令，在notebook code cell中显示图片\n%matplotlib inline","execution_count":10,"outputs":[]},{"metadata":{"collapsed":false,"id":"7C7EA9E6789A40B592F14B7BCFFF7F7B","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 用scatterplots去可视化特征的关系\nsns.pairplot(data, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=7, aspect=0.7, kind='reg')","execution_count":11,"outputs":[]},{"metadata":{"id":"C275D932F92048D0ACA6E4CE1F32587C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"[返回问题](#线性回归问题)"},{"metadata":{"id":"50A20C1D8EEB468AAB032EEB27D8AE45","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 4.线性回归\n\n**优点:** 快速，可推断，易于理解\n\n**缺点:** 很难去得到最佳准确性，因为它在特征值和响应值上假设了一个线性关系。"},{"metadata":{"id":"73988E56B49C428A8FA4600180E047A3","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.1线性回归公式\n\n$$ \ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n \n$$\n\n- ~$y~$ is the response\n- ~$\\beta_0~$ is the intercept\n- ~$\\beta_1~$ is the coefficient for ~$x_1~$ (the first feature)\n- ~$\\beta_n~$ is the coefficient for ~$x_n~$ (the nth feature)\n\n在这个例子中:\n\n~$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times radio + \\beta_3 \\times newspaper~$\n\nThe ~$\\beta~$ values are called the **model coefficients**. These values are \"learned\" during the model fitting step using the \"least squares\" criterion. Then, the fitted model can be used to make predictions!"},{"metadata":{"id":"90C91C94268E4DAC8EE5DFFDFC4B07B1","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.2用```pandas```预处理```X```和```y```\n\n- ```scikit-learn``` 要求 ```X``` (特征矩阵) 和 ```y``` (对应向量)是 ```NumPy```数组。\n- 然而，```pandas```是基于 ```Numpy```构建的。\n- 因此，```X``` 可以是 ```pandas```数据框(DataFrame)，```y``` 可以是数组(Series)"},{"metadata":{"collapsed":false,"id":"FEC68080218F4139BC56E2EB9AE76463","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 创建一个Python list存储特征名称\nfeature_cols = ['TV', 'Radio', 'Newspaper']\n\n# 用这个list去选择原始数据框的子集\nX = data[feature_cols]\n\n# 等效的方式\n# X = data[['TV', 'Radio', 'Newspaper']]\n\n# 打印前五行\nX.head()","execution_count":12,"outputs":[]},{"metadata":{"collapsed":false,"id":"A42D0A2DCB2548CC99682867FB468E22","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 检查X的类型和形状\nprint(type(X))\nprint(X.shape)","execution_count":13,"outputs":[]},{"metadata":{"collapsed":false,"id":"A26F36036B394057A55C33FDE0096C88","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 在DataFrame中选择一个Series\ny = data['Sales']\n\n# 等效的方式\n# y = data.sales\n\n# 打印前五行\ny.head()","execution_count":14,"outputs":[]},{"metadata":{"collapsed":false,"id":"6777756634E442FBB239226630C2640D","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# check the type and shape of y\nprint(type(y))\nprint(y.shape)","execution_count":15,"outputs":[]},{"metadata":{"id":"11D592AEE0EA4281B73D3632E8187878","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.3将数据集拆分成训练子集```X```和测试子集``` y```"},{"metadata":{"collapsed":false,"id":"A42944B8D7D5428E88BDCC6FABC4716F","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","execution_count":16,"outputs":[]},{"metadata":{"collapsed":false,"id":"30E267A6EDEA4B0390E6414E416CA514","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 默认的方式是 75%做训练集，25%做测试集\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":17,"outputs":[]},{"metadata":{"id":"DD8DCE36140747848E35DEB57102E7D1","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.4在```scikit-learn```中使用线性回归"},{"metadata":{"collapsed":false,"id":"D304252595124E668630B86C52D04807","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 导入模型\nfrom sklearn.linear_model import LinearRegression\n# 初始化\nlinreg = LinearRegression()\n# fit model\nlinreg.fit(X_train, y_train)","execution_count":18,"outputs":[]},{"metadata":{"id":"2FDE9C4AD4824764A8E8F9318B61AB39","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.5推断模型的相关系数"},{"metadata":{"collapsed":false,"id":"1E0F9B4201AA470FA43DBEA5DC309592","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"#打印 intercept 和 coefficients \nprint(linreg.intercept_)\nprint(linreg.coef_)","execution_count":19,"outputs":[]},{"metadata":{"collapsed":false,"id":"CAD29A3550F942329D17D12948B55B0B","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 找寻特征与其相应的系数\nlist(zip(feature_cols, linreg.coef_))","execution_count":20,"outputs":[]},{"metadata":{"id":"109808C5F19B4334B20EEE2709A93133","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"~$y = 2.88 + 0.0466 \\times TV + 0.179 \\times radio + 0.00345 \\times newspaper~$\n\n重要提示:\n\n- 这个声明是一个**关联**, 而非**因果**.\n- 如果电视广告花费(TV ad spending)的增加与销售(sales)的减少为关联，那么$\\beta_1$将为**负**."},{"metadata":{"id":"0E904F72B6894AD69DCBD8B15D1B9BAB","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.6做预测"},{"metadata":{"collapsed":false,"id":"42F653736AA949D0952BB84E3D7E6F62","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 基于测试子集做预测\ny_pred = linreg.predict(X_test)","execution_count":21,"outputs":[]},{"metadata":{"id":"7232BDB9FE894324A3374984AF48CF76","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们需要一个**评价指标**去对比预测值和真实值！"},{"metadata":{"id":"269FB57EF1E94A8081CCBB3465B24A56","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.7回归模型的评价指标    "},{"metadata":{"collapsed":false,"id":"50CAFD3C676241DD9D2D0D462D126529","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# define true and predicted response values00\ntrue = [100, 50, 30, 20]\npred = [90, 50, 50, 30]","execution_count":22,"outputs":[]},{"metadata":{"id":"D00627FC1C1B4A12B804D59D7EEF9DBC","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"**Mean Absolute Error** (MAE) 是绝对平均误差\n\n$$\n\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|\n$$"},{"metadata":{"collapsed":false,"id":"8CBC2F487FC1439F81E7F539C0001CF9","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 手算MAE\nprint((10 + 0 + 20 + 10)/4.)\n\n# 用 scikit-learn计算MAE\nfrom sklearn import metrics\nprint(metrics.mean_absolute_error(true, pred))","execution_count":23,"outputs":[]},{"metadata":{"id":"AADBA8253B8347798B02BBCE5AF6B8D0","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"**Mean Squared Error** (MSE) 是均方误差:\n\n$$\n\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2\n$$"},{"metadata":{"collapsed":false,"id":"E2C676891F5A416C9DDA4076948BD0CA","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 手算MSE\nprint((10**2 + 0**2 + 20**2 + 10**2)/4.)\n\n# 用scikit-learn计算MSE\nprint(metrics.mean_squared_error(true, pred))","execution_count":24,"outputs":[]},{"metadata":{"id":"1320B0D0A01A42CFB238B7A1C503E180","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"**Root Mean Squared Error** (RMSE) 是均方根误差:\n\n~$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}~$"},{"metadata":{"collapsed":false,"id":"6F198191AD8C47FABBC196D312D4D237","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 手算RMSE\nimport numpy as np\nprint(np.sqrt((10**2 + 0**2 + 20**2 + 10**2)/4.))\n\n# 用scikit-learn计算RMSE\nprint(np.sqrt(metrics.mean_squared_error(true, pred)))","execution_count":25,"outputs":[]},{"metadata":{"id":"05FD2480F08C494290E9ABB4B7A0FD0C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"对比这些指标:\n\n- **MAE**:最容易理解，因为它是平均误差\n- **MSE**:比MAE流行，因为它“惩罚”了较大的误差\n- **RMSE**:比MSE更流行，因为RMSE对```y```是可推测的"},{"metadata":{"id":"1174AA4591B942C4A5BC376D85663202","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"**计算sales预测值的RMSE**"},{"metadata":{"collapsed":false,"id":"B562A97980794A75AB3062619A1DF820","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":26,"outputs":[]},{"metadata":{"id":"2E9DCE732AFA452F8F75B37605063ED3","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 4.8特征选择\n\n**newspaper**是否属于我们的模型？换句话说，移除它之后会影响我们的预测麽？    \n我们在模型中**移除newspaper**重新来检测RMSE！"},{"metadata":{"collapsed":false,"id":"6E0DBC1EA4534F019BDA119CD8351F40","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 创建一个Python list存储特征名称\nfeature_cols = ['TV', 'Radio']\n\n# 用这个list去选择原始数据框的子集\nX = data[feature_cols]\n\n# 在DataFrame中选择一个Series\ny = data.Sales\n\n# 拆分数据集\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n# fit模型\nlinreg.fit(X_train, y_train)\n\n# 基于测试子集做预测\ny_pred = linreg.predict(X_test)\n\n# 计算预测值的RMSE\nprint(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":27,"outputs":[]},{"metadata":{"id":"F86FB70A510D4662AF4A8861443148F9","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"当我们在模型中移除**newspaper**之后，RMSE降低(误差是我们想要减小的，**一个小数值的RMSE更好** )。因此，这个特征对于预测sales不是很有用，应该从模型中移除。    \n\n[返回问题](#线性回归问题)"},{"metadata":{"id":"506FE333C319443F9749FDA225BA2A43","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 5.参考资料\n\n线性回归:\n\n- [Longer notebook on linear regression](https://github.com/justmarkham/DAT5/blob/master/notebooks/09_linear_regression.ipynb)\n- [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) & [related videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n- [Quick reference guide to applying and interpreting linear regression](http://www.dataschool.io/applying-and-interpreting-linear-regression/)\n- [Introduction to linear regression](http://people.duke.edu/~rnau/regintro.htm)\n\npandas:\n\n- [Three-part pandas tutorial](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/)\n- [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) & [read_table](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html) \n\nseaborn:\n\n- [Official seaborn tutorial](http://web.stanford.edu/~mwaskom/software/seaborn/tutorial.html)\n- [Example gallery](http://web.stanford.edu/~mwaskom/software/seaborn/examples/index.html)   \n\n[返回问题](#线性回归问题)    \n[返回目录](#目录)"},{"metadata":{"id":"8E7651D6EB2D4829B6A0A29D75E97BBF","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"# 分类问题\n\n1. [问题介绍](#1.问题介绍) \n\n2. [检查数据](#2.检查数据)\n\n3. [处理数据](#3.处理数据)\n\n4. [探索性分析](#4.探索性分析)\n\n5. [分类Classification](#5.分类Classification)  \n    - [5.1交叉检验](#5.1交叉检验)\n\n    - [5.2参数调整](#5.2参数调整)\n\n6. [全过程的复用性](#6.全过程的复用性)"},{"metadata":{"id":"0E6FA9BAAA844FE887126236C7822FBD","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 1.问题介绍\n    \nIris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。在这个问题中，我们在原有数据的基础上，加入了一些**扰动因素(dirty data)**,增加了问题的难度。\n[返回问题](#分类问题)"},{"metadata":{"id":"0438D751ECE94381BBED251F38CAE536","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 2.检查数据\n\n我们用pandas导入原始数据到数据框中"},{"metadata":{"collapsed":false,"id":"46EDE03AE7B848FEAA199ED9C7AEF97D","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"import pandas as pd\n\niris_data = pd.read_csv('../input/mwstart/Iris-data.csv')\niris_data.head()","execution_count":5,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n0              5.1             3.5              1.4             0.2   \n1              4.9             3.0              1.4             0.2   \n2              4.7             3.2              1.3             0.2   \n3              4.6             3.1              1.5             0.2   \n4              5.0             3.6              1.4             0.2   \n\n         class  \n0  Iris-setosa  \n1  Iris-setosa  \n2  Iris-setosa  \n3  Iris-setosa  \n4  Iris-setosa  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":5}]},{"metadata":{"id":"9F0FC1CFE40543A5BB11122E334E7F2C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"数据的第一行定义了数据头，紧随其后的每一行代表了每一种花对应的四个测量数据。**我们要做的第一件事就是检查缺失数据**。可以在pandas中对缺失值定义一个marker，如下："},{"metadata":{"collapsed":false,"id":"30E6542F0FCA4CAA88BEFCAD80A91C68","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data = pd.read_csv('../input/mwstart/Iris-data.csv',na_values=['NA'])","execution_count":6,"outputs":[]},{"metadata":{"id":"8A81E7CC9D924E6990E47E8804DEE15A","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"下面我们需要看看数据的分布，尤其对于那些异常值。让我们来打印一个数据集的描述性统计摘要。"},{"metadata":{"collapsed":false,"id":"D83EA8FB782B40F090C33C5B00C90A62","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.describe()","execution_count":7,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"       sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm\ncount       150.000000      150.000000       150.000000      145.000000\nmean          5.644627        3.054667         3.758667        1.236552\nstd           1.312781        0.433123         1.764420        0.755058\nmin           0.055000        2.000000         1.000000        0.100000\n25%           5.100000        2.800000         1.600000        0.400000\n50%           5.700000        3.000000         4.350000        1.300000\n75%           6.400000        3.300000         5.100000        1.800000\nmax           7.900000        4.400000         6.900000        2.500000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>145.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.644627</td>\n      <td>3.054667</td>\n      <td>3.758667</td>\n      <td>1.236552</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.312781</td>\n      <td>0.433123</td>\n      <td>1.764420</td>\n      <td>0.755058</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.055000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.700000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":7}]},{"metadata":{"id":"0286C6AD4A9E4FCD9A75E227AF992BAD","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"从上表中，我们可以看到`petal_width_cm`这一列中有5个缺失值。相比于列表显示数据特征，可视化是一个更好的选择。因为可视化可以让异常值和误差被直接展示出来。"},{"metadata":{"collapsed":false,"id":"3E78937329E34E9EB5FE79BB4FBB0652","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 这一行代码告诉Notebook在cell中显示图片\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":8,"outputs":[]},{"metadata":{"id":"53244A8CA13A45628CA18B913D3EDC86","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"下面，我们打印一个散点图矩阵。在这个矩阵的对角线上，每一列的分布将会被打印出来。变量两两配对组合的结果将会在其余位置打印出来。我们甚至可以设置参数，将每一类花朵(class)的内容分别打印出来，便于查看趋势。"},{"metadata":{"collapsed":false,"id":"1867EAF2FCC744D1912D5716732FCE11","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 在打印时，我们暂时移除了缺失值，因为seaborn绘图函数不知道如何处理他们。\nsns.pairplot(iris_data.dropna(), hue='class')","execution_count":9,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<seaborn.axisgrid.PairGrid at 0x7f12e0050748>"},"execution_count":9},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 821.125x720 with 20 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/2A4ACD7EC463449B8FD9427BCABD9FAC/qrtg8yjtgo.png\">"},"transient":{}}]},{"metadata":{"id":"A88EB6B8A63B4971A45EB513A251A210","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"从散点图矩阵中我们可以看出数据集中的一些问题：\n1. 散点图中显示出数据集包含5个class，然而应该只有3个class，这意味着数据集中有一些coding error。\n2. 有一些明显的异常值可能是coding error导致的。\n3. 我们需要drop掉有缺失值的行。\n\n在以上的问题中，我们需要对这些有问题的数据进行处理。  \n\n[返回问题](#分类问题)"},{"metadata":{"id":"C424553769C84389AE63F1E4968C94DD","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 3.处理数据\n\n现在我们找到了数据集中的一些错误，在分析之前，我们需要逐个修复它们。\n\n>散点图中显示出数据集包含5个class，然而应该只有3个class，这意味着数据集中有一些coding error。   \n\n```versicolor```之前应该有```Iris-```前缀，```Iris-setossa```应该是拼写错误，实际为```Iris-setosa```.   \n我们利用数据框(DataFrame)去修复这些问题。"},{"metadata":{"collapsed":false,"id":"A3C1577EDA9F4A1298BA7973C3304158","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[iris_data['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\niris_data.loc[iris_data['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n\niris_data['class'].unique()","execution_count":10,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"},"execution_count":10}]},{"metadata":{"id":"AAAA15A635FE46C999450981D8606BD8","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":">有一些明显的异常值可能是coding error导致的。\n\n通过研究，```Iris-setosa```的```sepal_width_cm```是不可能低于2.5 cm的，显然在数据集中有错误的地方。为方便后续的分析，我们直接drop掉这些有明显错误的地方。"},{"metadata":{"collapsed":false,"id":"EA3C1F64D8DC44728F2C0C0C3EF4B002","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"# 这一行代码drop掉了'Iris-setosa'中'separal_width'小于2.5cm的所有行\niris_data = iris_data.loc[(iris_data['class'] != 'Iris-setosa') | (iris_data['sepal_width_cm'] >= 2.5)]\niris_data.loc[iris_data['class'] == 'Iris-setosa', 'sepal_width_cm'].hist()","execution_count":11,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f12dd4aaf60>"},"execution_count":11},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3C308C91607345D3B79BDDDA5E904D51/qrtg99cfvh.png\">"},"transient":{}}]},{"metadata":{"id":"CE43E9A5E4474952BF5573C33ED032C2","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在所有的`Iris-setosa`对应的S都大于2.5 cm。   \n下一个issue是解决在`Iris-versicolor`一些`sepal_length_cm`接近0的数据行。   \n我们来看看这些数据。"},{"metadata":{"collapsed":false,"id":"0BF9AB7B6C2B4C69A2D9DF7AE55C3F7C","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n              (iris_data['sepal_length_cm'] < 1.0)]","execution_count":12,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"    sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n77            0.067             3.0              5.0             1.7   \n78            0.060             2.9              4.5             1.5   \n79            0.057             2.6              3.5             1.0   \n80            0.055             2.4              3.8             1.1   \n81            0.055             2.4              3.7             1.0   \n\n              class  \n77  Iris-versicolor  \n78  Iris-versicolor  \n79  Iris-versicolor  \n80  Iris-versicolor  \n81  Iris-versicolor  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>77</th>\n      <td>0.067</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>1.7</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.060</td>\n      <td>2.9</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.057</td>\n      <td>2.6</td>\n      <td>3.5</td>\n      <td>1.0</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.055</td>\n      <td>2.4</td>\n      <td>3.8</td>\n      <td>1.1</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>0.055</td>\n      <td>2.4</td>\n      <td>3.7</td>\n      <td>1.0</td>\n      <td>Iris-versicolor</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":12}]},{"metadata":{"id":"00D810006FE34058A27BB53C2CC41889","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"这些数据看起来像是被缩小了100倍，就像是他们被记录的单位是米而非厘米。在查阅资料后，我们重新修复这些数据。"},{"metadata":{"collapsed":false,"id":"EA504F01230D42B38539A366D65660E0","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n              (iris_data['sepal_length_cm'] < 1.0),\n              'sepal_length_cm'] *= 100.0\n\niris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist()","execution_count":13,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f12dd7f3ef0>"},"execution_count":13},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3D22E88F8F3045778ED07CC8ABE21C23/qrtg9fy2ba.png\">"},"transient":{}}]},{"metadata":{"id":"4C3DFDFA8AF44331B4712FD3102E9994","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":">我们需要drop掉有缺失值的行。\n\n我们先来看看这些有缺失值的行"},{"metadata":{"collapsed":false,"id":"CF00530ABDFE499EB7C37FA6B5985322","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n              (iris_data['sepal_width_cm'].isnull()) |\n              (iris_data['petal_length_cm'].isnull()) |\n              (iris_data['petal_width_cm'].isnull())]","execution_count":14,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"    sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n7               5.0             3.4              1.5             NaN   \n8               4.4             2.9              1.4             NaN   \n9               4.9             3.1              1.5             NaN   \n10              5.4             3.7              1.5             NaN   \n11              4.8             3.4              1.6             NaN   \n\n          class  \n7   Iris-setosa  \n8   Iris-setosa  \n9   Iris-setosa  \n10  Iris-setosa  \n11  Iris-setosa  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>NaN</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>NaN</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>NaN</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>NaN</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>NaN</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":14}]},{"metadata":{"id":"29ACE2BE4FFC48BC91D4C39995FE8FFB","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"Drop掉这些有缺失值的数据并不是一个理想的方法，因为它们都属于`Iris-setosa`这个类别中，像是系统性地缺失。   \n处理缺失值的一个方法就是**平均数插补**:如果我们知道数值的度量在一个范围内，我们可以取度量的平均值去填补缺失的地方。     \n试试看我们可否在这里用平均数插补。"},{"metadata":{"collapsed":false,"id":"ECD60E838AB8477EA96591DEF63DC239","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].hist()","execution_count":15,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f12dc303278>"},"execution_count":15},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/43792692DAEF41969BADA9A9D2B35096/qrtg9kyipn.png\">"},"transient":{}}]},{"metadata":{"id":"55DB6D54A18F4AF5ACED3C5D4CE9F064","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"大多数`Iris-setosa`的petal_width落在了0.2-0.3的区间内，我们用平均值去填补数据缺失的部分。"},{"metadata":{"collapsed":false,"id":"F00CE6F8387946FBA4FA64F815A3D892","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"average_petal_width = iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].mean()\n\niris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n              (iris_data['petal_width_cm'].isnull()),\n              'petal_width_cm'] = average_petal_width\n\niris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n              (iris_data['petal_width_cm'] == average_petal_width)]","execution_count":16,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"    sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n7               5.0             3.4              1.5            0.25   \n8               4.4             2.9              1.4            0.25   \n9               4.9             3.1              1.5            0.25   \n10              5.4             3.7              1.5            0.25   \n11              4.8             3.4              1.6            0.25   \n\n          class  \n7   Iris-setosa  \n8   Iris-setosa  \n9   Iris-setosa  \n10  Iris-setosa  \n11  Iris-setosa  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.25</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.25</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.25</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.25</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>0.25</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":16}]},{"metadata":{"collapsed":false,"id":"43F34C4F625D496DB9BCDADE5862A086","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n              (iris_data['sepal_width_cm'].isnull()) |\n              (iris_data['petal_length_cm'].isnull()) |\n              (iris_data['petal_width_cm'].isnull())]","execution_count":17,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"Empty DataFrame\nColumns: [sepal_length_cm, sepal_width_cm, petal_length_cm, petal_width_cm, class]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length_cm</th>\n      <th>sepal_width_cm</th>\n      <th>petal_length_cm</th>\n      <th>petal_width_cm</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"execution_count":17}]},{"metadata":{"id":"256EBF11763F43339153BA3E58F6D129","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在我们的数据集里面没有了缺失值！\n\n为了日后的复用，我们将处理过的数据保存为一个新的文件。"},{"metadata":{"collapsed":false,"id":"FB53D0A160F54F0D967F2CB7117BF0D9","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data.to_csv('iris-data-clean.csv', index=False)\n\niris_data_clean = pd.read_csv('iris-data-clean.csv')","execution_count":18,"outputs":[]},{"metadata":{"id":"EDD4F334BA6E45CC92F8203E8F7BA23B","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在我们对清理过的数据绘制散点矩阵图。"},{"metadata":{"collapsed":false,"id":"39D140DA477742BEBAA699C3A1843710","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"sns.pairplot(iris_data_clean, hue='class')","execution_count":19,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<seaborn.axisgrid.PairGrid at 0x7f12dc284438>"},"execution_count":19},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 821.125x720 with 20 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/9204DCC04E76417FAAD8B0A214373F96/qrtga0ndu9.png\">"},"transient":{}}]},{"metadata":{"id":"DDDF390759774D759932824772F2DA42","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"通常清洗数据的方式：\n* 确保数据被合适解析(encode)。\n* 确保你的数据落在期望的区间内，合理运用常识去定义、判断期望的区间范围。\n* 用一种方式去处理缺失数据：替换它或者drop掉。\n* 尽量不要手动清洗数据，因为这样很难复用。\n* 用代码去记录清洗数据的过程。\n* 绘制尽可能多关于数据的可视化图，因为你可以*目测* 检验是否正确。  \n\n[返回问题](#分类问题)"},{"metadata":{"id":"D65413DFC873429692C66593623BB91F","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 4.探索性分析\n\n我们现在开始分析数据！    \n探索性分析是我们进一步了解数据的过程，这一过程中，我们将会试着回答类似如下的问题：\n\n* 数据是如何分布的？\n\n* 在数据中存在关联(corellations)吗？\n\n* 存在可以解释关联的因素(factors)吗?\n\n我们先回到之前绘制的散点矩阵图。"},{"metadata":{"collapsed":false,"id":"E5FA9A4B001640E986E9E33D4E8368E3","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"sns.pairplot(iris_data_clean)","execution_count":21,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<seaborn.axisgrid.PairGrid at 0x7f12d2f19828>"},"execution_count":21},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 720x720 with 20 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/7FD2CAF0CBE848A88373EE01893E63CF/qrtgbiknr8.png\">"},"transient":{}}]},{"metadata":{"id":"8604CF21E5624B8387637D8A257DAEA4","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们的大部分都是正态分布的，我们可以直接使用那些假设数据是正态分布的模型。\n\nPetal测量值看起来略显奇怪，也许是因为不同的Iris类型对应不同的测量值分布。我们按照不同的class去绘制散点矩阵图，如下："},{"metadata":{"collapsed":false,"id":"C1C9023E926A4F4094C0C29216521DCA","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"sns.pairplot(iris_data_clean, hue='class')","execution_count":22,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<seaborn.axisgrid.PairGrid at 0x7f12d23adbe0>"},"execution_count":22},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 821.125x720 with 20 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/1F52E0E6AD2145F8AA9CCF4C32A8B735/qrtgbr27o.png\">"},"transient":{}}]},{"metadata":{"id":"09F76029D22046DFBDAC5B91CF3B7516","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们也可以绘制**violin plots**去看每一类Iris花的测量值分布。"},{"metadata":{"collapsed":false,"id":"02E436D614634E608389D8D3FF0B54ED","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\nfor column_index, column in enumerate(iris_data_clean.columns):\n    if column == 'class':\n        continue\n    plt.subplot(2, 2, column_index + 1)\n    sns.violinplot(x='class', y=column, data=iris_data_clean)","execution_count":23,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 720x720 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/CB5F25B2495245AD8BA989EB50FFD099/qrtgbsqq9m.png\">"},"transient":{}}]},{"metadata":{"id":"B7377061C45D4007A64998E22A22A1FD","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"[返回问题](#分类问题)"},{"metadata":{"id":"D61C18EEB0CB44E3904B1BA24FB34DF5","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 5.分类Classification\n\n\n整理、探索数据对数据分析而言，是很重要的过程。如果我们忽略它直接去建模，我们很有可能会建立错误的模型。**Bad data leads to bad models.**\n\n我们将数据集划分为训练集和测试集两个部分。    \n**训练集** 是一个用来训练模型的原数据集的随机子集。is a random subset of the data that we use to train our models.    \n**测试集** 是一个用来测试模型的原数据集的随机子集(与训练集相互具有排他性)。\n\n在数据量稀疏的数据集中，很容易出现过拟合(`overfit`):模型很好地学习了训练集导致其无法应对测试集中这些从未出现过的样例。这就是为什么我们需要根据训练集建立模型，并且利用测试集给它打分。   \n\n我们首先来划分数据集。"},{"metadata":{"collapsed":false,"id":"64CDAF99AE00450BA7D1E481BC468C2A","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"iris_data_clean = pd.read_csv('../work/iris-data-clean.csv')\n\n# 我们使用所有的4个测量变量为input\n\n# 我们可以用如下的方式从pandas中提取数据\nall_inputs = iris_data_clean[['sepal_length_cm', 'sepal_width_cm',\n                             'petal_length_cm', 'petal_width_cm']].values\n\n# 同样的，我们可以提class\nall_classes = iris_data_clean['class'].values\n\n# Make sure that you don't mix up the order of the entries\n# all_inputs[5] inputs should correspond to the class in all_classes[5]\n# 确信你没有弄混数据的出现顺序\n# all_inputs[5] 是在all_classes中对应的class分类\n# all_inputs的一个子集如下所示\nall_inputs[:5]","execution_count":24,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2]])"},"execution_count":24}]},{"metadata":{"id":"45A0DC46DDEC4B9BA909E13FF99E217C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们的数据集已经完成了划分的准备。"},{"metadata":{"collapsed":false,"id":"6A6FC8F938E1421FB8D5CE48522749EF","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n(training_inputs,\n testing_inputs,\n training_classes,\n testing_classes) = train_test_split(all_inputs, all_classes, train_size=0.75, random_state=1)","execution_count":25,"outputs":[]},{"metadata":{"id":"066C07DFA65E4DFD9EB3D2CFE00C2614","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们的数据集完成了划分，现在我们尝试使用**决策树(Decision Tree)**去训练模型。"},{"metadata":{"collapsed":false,"id":"4500CA7940D047A7B082925C0CDC43B1","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# 建立分类器\ndecision_tree_classifier = DecisionTreeClassifier()\n\n# 用训练集去训练分类器\ndecision_tree_classifier.fit(training_inputs, training_classes)\n\n# 用测试集去检验训练好的分类器\ndecision_tree_classifier.score(testing_inputs, testing_classes)","execution_count":26,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"0.9736842105263158"},"execution_count":26}]},{"metadata":{"id":"268EDEFDF00946BC91EDEA44278E2CB1","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"不费吹灰之力，我们的模型达到了97%的分类正确率。\n然而，这里有个陷阱：根据训练集和测试集是如何采样的，我们的模型可以达到80% - 100%的正确率。"},{"metadata":{"collapsed":false,"id":"7AC28929D846432EAC1645552CEF0D81","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"model_accuracies = []\n\nfor repetition in range(1000):\n    (training_inputs,\n     testing_inputs,\n     training_classes,\n     testing_classes) = train_test_split(all_inputs, all_classes, train_size=0.75)\n    \n    decision_tree_classifier = DecisionTreeClassifier()\n    decision_tree_classifier.fit(training_inputs, training_classes)\n    classifier_accuracy = decision_tree_classifier.score(testing_inputs, testing_classes)\n    model_accuracies.append(classifier_accuracy)\n    \nsns.distplot(model_accuracies)","execution_count":27,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f12ceb27240>"},"execution_count":27},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/60C0E40785B940369B3AF8E1ECA604F9/qrtgrmgmfe.png\">"},"transient":{}}]},{"metadata":{"id":"D289EAAFCF1D4DE8B4BD019800267A27","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"这个现象就是过拟合(`overfitting`):模型很好地学习了训练集导致其无法应对测试集中这些从未出现过的样例。\n很显然，根据不同的训练子集，模型的表现有显著差别。"},{"metadata":{"id":"2B2C43D34482478181FA9B7949F9888F","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 5.1交叉检验\n\n针对过拟合(`overfitting`)问题，大多数数据科学家会对他们的模型使用***k*-fold cross-validation**：将原始数据集划分为*k*个子集，用其中一个子集作为测试集，剩下的所有子集用作训练集。这个过程将重复*k*次，每一个子集都有一次机会作为测试集。   \n\n10-fold cross-validation是最普遍的选择，在这里用它对我们的模型进行交叉检验。"},{"metadata":{"id":"6B395ABBD7994DD283F051C918ECEB08","notebookId":"607cf4d58807550018b0e45f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=10)\nt = iris_data.classes\nfor train, test in skf.split(np.zeros(len(t)), t):\n    train = dataset.loc[train_index]\n    test = dataset.loc[test_index]","execution_count":null},{"metadata":{"collapsed":false,"id":"9B94E18E24934EB4BACD063F2C156181","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n\ndef plot_cv(cv, n_samples):\n    masks = []\n    for train, test in cv:\n        mask = np.zeros(n_samples, dtype=bool)\n        mask[test] = 1\n        masks.append(mask)\n        \n    plt.figure(figsize=(15, 15))\n    plt.imshow(masks, interpolation='none')\n    plt.ylabel('Fold')\n    plt.xlabel('Row #')\nskf = StratifiedKFold(n_splits = 10)\nplot_cv(skf.split(all_inputs,all_classes), len(all_classes))","execution_count":66,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1080x1080 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/F281AED853CC475FA5C0F8685B51C9D6/qrtilpvu2t.png\">"},"transient":{}}]},{"metadata":{"id":"1489370040A0492DA1F7A75A86543E49","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"在上述过程中我们使用了**Stratified *k*-fold cross-validation**，它可以使得每一个fold都保留class proportions,这一点对于保持子集的代表性十分重要。       \n\n我们可以用以下的代码去对模型做10-fold cross-validation"},{"metadata":{"collapsed":false,"id":"A8C12C366E1F4EACB8681BF428D4219B","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ndecision_tree_classifier = DecisionTreeClassifier()\n\n# cross_val_score(cv_scores)返回了一个list，我们可以对它进行可视化，来查看分类器的表现 \ncv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_classes, cv=10)\nsns.distplot(cv_scores)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))\nplt.show()","execution_count":52,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B645B4517854F43B97BA36EEDB4B035/qrti37tayf.png\">"},"transient":{}}]},{"metadata":{"id":"526A7212EEE14FD4A3CFEE9091A0FBA2","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在我们有了一个相对稳定表现的分类器。"},{"metadata":{"id":"55382C2E610F4697BD8A3213F37A2C96","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"### 5.2参数调整\n\n每一个机器学习模型都有一系列的参数去调整，这些参数对于分类器的表现起到了重要作用。比如，我们控制决策树的`max_depth`。如下所示："},{"metadata":{"collapsed":false,"id":"BE4BCFDCF2C44C4FA26F7F7B19AAE7B6","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"decision_tree_classifier = DecisionTreeClassifier(max_depth=1)\n\ncv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_classes, cv=10)\nsns.distplot(cv_scores, kde=False)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))\nplt.show()","execution_count":53,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/58EB2DC9E23D48A08927F3111B8B5B22/qrti3eqw96.png\">"},"transient":{}}]},{"metadata":{"id":"980A8508EEB34ECE94137FA25EEEE055","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"分类器的准确率下降十分显著！\n\n因此我们需要选择一个系统性的方法去探索对我们的模型和数据最佳的参数值。\n\n最常用的参数调整方式是**Grid Search**,原理很简单：探索一个范围内的参数值，选择达到最佳表现的参数组合。\n\n我们对决策树分类器进行调参。现在我们仅仅关注```max_depth```和```max_features```这两个参数上，当然也可以同时探索多个参数。"},{"metadata":{"collapsed":false,"id":"6C2D52654A084E1EAB1376B731CE21C5","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndecision_tree_classifier = DecisionTreeClassifier()\n\nparameter_grid = {'max_depth': [1, 2, 3, 4, 5],\n                  'max_features': [1, 2, 3, 4]}\n\ncross_validation = StratifiedKFold(n_splits=10)\n\ngrid_search = GridSearchCV(decision_tree_classifier,\n                           param_grid=parameter_grid,\n                           cv=cross_validation)\n\ngrid_search.fit(all_inputs, all_classes)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))","execution_count":54,"outputs":[{"output_type":"stream","text":"Best score: 0.9664429530201343\nBest parameters: {'max_depth': 5, 'max_features': 3}\n","name":"stdout"}]},{"metadata":{"id":"F7F19398C72E486986E92CFD11062E09","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们现在去可视化**grid search**的过程，去看看参数之间如何相互作用。"},{"metadata":{"collapsed":false,"id":"592EC11E3F95412198744C945ED085C7","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"grid_visualization = []\n\nfor grid_pair in grid_search.cv_results_['mean_test_score']:\n    grid_visualization.append(grid_pair)\n","execution_count":71,"outputs":[]},{"metadata":{"id":"3E0A4286B946484E8EC5AAEB1DB5391B","notebookId":"607cf4d58807550018b0e45f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/9AEC5C84B36C49188855594C4246F711/qrtja8ghbl.png\">"},"transient":{}}],"source":"grid_visualization = np.array(grid_visualization)\ngrid_visualization.shape = (5, 4)\nsns.heatmap(grid_visualization, cmap='Blues')\nplt.xticks(np.arange(4) + 0.5, grid_search.param_grid['max_features'])\nplt.yticks(np.arange(5) + 0.5, grid_search.param_grid['max_depth'][::-1])\nplt.xlabel('max_features')\nplt.ylabel('max_depth')\nplt.show()","execution_count":72},{"metadata":{"id":"95A66C417F2649349799A505711ED17B","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在我们尝试调整更多的参数去优化模型。"},{"metadata":{"collapsed":false,"id":"6577647A68E14DAE95B37A2BC8A4CC24","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"decision_tree_classifier = DecisionTreeClassifier()\n\nparameter_grid = {'criterion': ['gini', 'entropy'],\n                  'splitter': ['best', 'random'],\n                  'max_depth': [1, 2, 3, 4, 5],\n                  'max_features': [1, 2, 3, 4]}\n\ncross_validation = StratifiedKFold(n_splits =10)\n\ngrid_search = GridSearchCV(decision_tree_classifier,\n                           param_grid=parameter_grid,\n                           cv=cross_validation)\n\ngrid_search.fit(all_inputs, all_classes)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))","outputs":[{"output_type":"stream","text":"Best score: 0.9664429530201343\nBest parameters: {'criterion': 'gini', 'max_depth': 4, 'max_features': 3, 'splitter': 'best'}\n","name":"stdout"}],"execution_count":80},{"metadata":{"id":"BB2DA9113BEE41E08D3CBAEF56A343A4","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们将找到的最佳参数组合用于我们的分类器模型中"},{"metadata":{"collapsed":false,"id":"48804DF0C4514CB9B7F3682A37931478","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"decision_tree_classifier = grid_search.best_estimator_\ndecision_tree_classifier","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n                       max_features=3, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')"},"execution_count":81}],"execution_count":81},{"metadata":{"id":"59B8EE41FE984637A2FEF35FDAEE3D7F","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们终于有了最佳分类器模型，现在去对其表现做可视化。"},{"metadata":{"collapsed":false,"id":"F45751FC97C2471992C06A3B858AD201","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"dt_scores = cross_val_score(decision_tree_classifier, all_inputs, all_classes, cv=10)\n\nsns.boxplot(dt_scores)\nsns.stripplot(dt_scores, jitter=True, color='white')","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f12ce4b37b8>"},"execution_count":82},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A9A5F89AD2AC4452909C5C82FD3543F6/qrtjh1fdy6.png\">"},"transient":{}}],"execution_count":82},{"metadata":{"id":"0A8D0CA94D4E46E9AD444ED38E5F338C","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"我们引入一个新的分类器**随机森林**,去和之前的**决策树**做对比。"},{"metadata":{"collapsed":false,"id":"5B915D4DABB3484ABEBB0E8F2A322540","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest_classifier = RandomForestClassifier()\n\nparameter_grid = {'n_estimators': [5, 10, 25, 50],\n                  'criterion': ['gini', 'entropy'],\n                  'max_features': [1, 2, 3, 4],\n                  'warm_start': [True, False]}\n\ncross_validation = StratifiedKFold(n_splits=10)\n\ngrid_search = GridSearchCV(random_forest_classifier,\n                           param_grid=parameter_grid,\n                           cv=cross_validation)\n\ngrid_search.fit(all_inputs, all_classes)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\ngrid_search.best_estimator_","outputs":[{"output_type":"stream","text":"Best score: 0.9664429530201343\nBest parameters: {'criterion': 'gini', 'max_features': 4, 'n_estimators': 5, 'warm_start': True}\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=4, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=5,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=True)"},"execution_count":84}],"execution_count":84},{"metadata":{"id":"37C0EC6BA5734C1DBBBB5008B4554E7A","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"现在我们可以对比两个分类器的表现："},{"metadata":{"collapsed":false,"id":"15D08B4EDAB645ED9E7E1A00236D5845","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"random_forest_classifier = grid_search.best_estimator_\n\nrf_df = pd.DataFrame({'accuracy': cross_val_score(random_forest_classifier, all_inputs, all_classes, cv=10),\n                       'classifier': ['Random Forest'] * 10})\ndt_df = pd.DataFrame({'accuracy': cross_val_score(decision_tree_classifier, all_inputs, all_classes, cv=10),\n                      'classifier': ['Decision Tree'] * 10})\nboth_df = rf_df.append(dt_df)\n\nsns.boxplot(x='classifier', y='accuracy', data=both_df)\nsns.stripplot(x='classifier', y='accuracy', data=both_df, jitter=True, color='white')\nplt.show()","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/AB663F6109164B76BCB2DCDF9CC402D0/qrtjhs2e3z.png\">"},"transient":{}}],"execution_count":85},{"metadata":{"id":"50FC5E0F11034BA09BB649FE1C9DFAB4","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"看起来两个分类器在这个数据集上的表现很相似，这很有可能是因为数据集自身的限制：我们仅仅有4个特征去做分类，并且随机森林模型在数据集有多个特征的时候表现更好。简言之，对于这个数据集而言，两个模型没有多少可以进一步提升的地方。   \n\n[返回问题](#分类问题)"},{"metadata":{"id":"F0A76DCAED3F4C0DA860F4A187DD6BC6","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"## 6.全过程的复用性\n\n整个workflow最重要的一点就是可以被复用，我们写的代码做的分析要具有复用性。我们将之前的步骤整理成一个可以复刻的pipeline"},{"metadata":{"collapsed":false,"id":"FE62E67C046145BEA27A67A95BFFDF16","scrolled":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport seaborn as sb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# 直接用完成整理的数据集，因为我们之前做了保存\niris_data_clean = pd.read_csv('iris-data-clean.csv')\n\n# 通过以下代码对清洗过的数据集做测试\nassert len(iris_data_clean['class'].unique()) == 3\n\nassert iris_data_clean.loc[iris_data_clean['class'] == 'Iris-versicolor', 'sepal_length_cm'].min() >= 2.5\n\n\nassert len(iris_data_clean.loc[(iris_data_clean['sepal_length_cm'].isnull()) |\n                               (iris_data_clean['sepal_width_cm'].isnull()) |\n                               (iris_data_clean['petal_length_cm'].isnull()) |\n                               (iris_data_clean['petal_width_cm'].isnull())]) == 0\n\n# input \nall_inputs = iris_data_clean[['sepal_length_cm', 'sepal_width_cm',\n                             'petal_length_cm', 'petal_width_cm']].values\n\nall_classes = iris_data_clean['class'].values\n\n# 分类器 & Grid Search\nrandom_forest_classifier = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                                max_depth=None, max_features=3, max_leaf_nodes=None,\n                                min_samples_leaf=1, min_samples_split=2,\n                                min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n                                oob_score=False, random_state=None, verbose=0, warm_start=True)\n\n# cross-validation scores\nrf_classifier_scores = cross_val_score(random_forest_classifier, all_inputs, all_classes, cv=10)\nsb.boxplot(rf_classifier_scores)\nsb.stripplot(rf_classifier_scores, jitter=True, color='white')\n\n\n# 展示其中分类器预测结果的一部分\n(training_inputs,\n testing_inputs,\n training_classes,\n testing_classes) = train_test_split(all_inputs, all_classes, train_size=0.75)\n\nrandom_forest_classifier.fit(training_inputs, training_classes)\n\nfor input_features, prediction, actual in zip(testing_inputs[:10],\n                                              random_forest_classifier.predict(testing_inputs[:10]),\n                                              testing_classes[:10]):\n    print('{}\\t-->\\t{}\\t(Actual: {})'.format(input_features, prediction, actual))","outputs":[{"output_type":"stream","text":"[6.9 3.1 4.9 1.5]\t-->\tIris-versicolor\t(Actual: Iris-versicolor)\n[4.6 3.2 1.4 0.2]\t-->\tIris-setosa\t(Actual: Iris-setosa)\n[5.5 2.4 3.8 1.1]\t-->\tIris-versicolor\t(Actual: Iris-versicolor)\n[6.7 3.3 5.7 2.1]\t-->\tIris-virginica\t(Actual: Iris-virginica)\n[5.1 3.8 1.6 0.2]\t-->\tIris-setosa\t(Actual: Iris-setosa)\n[6.7 3.  5.2 2.3]\t-->\tIris-virginica\t(Actual: Iris-virginica)\n[6.5 3.2 5.1 2. ]\t-->\tIris-virginica\t(Actual: Iris-virginica)\n[6.3 2.5 5.  2.3]\t-->\tIris-virginica\t(Actual: Iris-virginica)\n[6.5 2.8 4.6 1.5]\t-->\tIris-versicolor\t(Actual: Iris-versicolor)\n[7.4 2.8 6.1 1.9]\t-->\tIris-virginica\t(Actual: Iris-virginica)\n","name":"stdout"},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/36DB26126AD34D5484D1A55F4D08C207/qrtjj99oof.png\">"},"transient":{}}],"execution_count":87},{"metadata":{"id":"34D9375AA0AA43EA8F3B0EFACC3B8981","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"[返回问题](#分类问题)   \n[返回目录](#目录)"},{"metadata":{"id":"52B11D3A20D64269841876276A6EF69D","mdEditEnable":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"markdown","source":"# 欢迎使用ModelWhale开启你的数据分析之旅！"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}