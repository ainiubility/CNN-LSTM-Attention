{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d55da8922213"
      },
      "source": [
        "```python\n",
        "tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
        "\n",
        "```\n",
        "\n",
        "-   `indices`: 整数张量，包含了要转换为 one-hot 编码的索引值。\n",
        "-   `depth`: 表示 one-hot 向量的长度，即总类别的数量。\n",
        "-   `on_value` 和 `off_value`: 分别指定 one-hot 向量中激活位（对应索引）和非激活位的值，默认为1和0。\n",
        "-   `axis`: 指定 one-hot 向量应该添加在哪一轴上，默认情况下将其添加为新的最末尾轴。\n",
        "-   `dtype`: 指定输出张量的数据类型，默认为 `tf.float32`。\n",
        "-   `name`: 可选的命名空间名称，用于区分不同的运算。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "837c12c320d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-11 19:51:40.926471: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-03-11 19:51:40.946512: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-11 19:51:40.946535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-11 19:51:40.947007: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-11 19:51:40.950262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-11 19:51:41.348839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-11 19:51:41.857368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.872663: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.872696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.875410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.875441: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.875452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.977901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.977940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.977945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2024-03-11 19:51:41.977964: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-03-11 19:51:41.977975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8990 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1, 10), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pip install pandas matplotlib scikit-learn-intelex scikit-learn openpyxl tensorboard seaborn\n",
        "\n",
        "from numpy import disp\n",
        "import tensorflow as tf  # version : '1.12.0'\n",
        "\n",
        "NUM_CLASSES = 10 # 10分类\n",
        "labels = [0,1,2,3] # sample label\n",
        "batch_size = tf.size(labels) # get size of labels : 4\n",
        "labels = tf.expand_dims(labels, 1) # 增加一个维度\n",
        "indices = tf.expand_dims(tf.range(0, batch_size,1), 1) #生成索引\n",
        "concated = tf.concat([indices, labels] , 1) #作为拼接\n",
        "# onehot_labels = tf.one_hot(concated, tf.stack([batch_size, NUM_CLASSES]), 1.0, 0.0) # 生成one-hot编码的标签\n",
        "\n",
        "# 使用tf.one_hot直接将稀疏标签转换为one-hot编码\n",
        "onehot_labels = tf.one_hot(labels, depth=NUM_CLASSES)\n",
        "\n",
        "display(onehot_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ca064b4f1232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]], shape=(4, 5), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]], shape=(5, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[1. 0. 0.]\n",
            "  [0. 1. 0.]]\n",
            "\n",
            " [[0. 1. 0.]\n",
            "  [1. 0. 0.]]], shape=(2, 2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]], shape=(4, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 得到4个5维独热行向量向量,\n",
        "#    其中第1个向量的第0个分量是独热1，\n",
        "#    第2个向量的第2个分量是独热，\n",
        "#    第3个向量没有独热，因为指定为-1\n",
        "#    第4个向量的第1个分量为独热\n",
        "# labels向targets的转变\n",
        "labels = [0, 2, -1, 1]\n",
        "# labels是shape=(4,)的张量。则返回的targets是shape=(len(labels), depth)张量。\n",
        "# 且这种情况下,axis=-1等价于axis=1\n",
        "targets = tf.one_hot(indices=labels, depth=5, on_value=1.0, off_value=0.0, axis=-1)\n",
        "\n",
        "print(targets)\n",
        "\n",
        "\n",
        "# 得到1个5维独热行向量。\n",
        "targets = tf.one_hot(indices=3, depth=5, on_value=1.0, off_value=0.0, axis=0)\n",
        "\n",
        "print(targets)\n",
        "\n",
        "# 得到1个5维独热列向量\n",
        "targets = tf.one_hot(indices=[3], depth=5, on_value=1.0, off_value=0.0, axis=0)\n",
        "\n",
        "print(targets)\n",
        "\n",
        "targets = tf.one_hot(indices=[[0,1],[1,0]], depth=3)\n",
        "\n",
        "print(targets)\n",
        " \n",
        "# 确保 labels 是一个 NumPy 数组或者类似的数据结构\n",
        "labels = np.array([0, 1, 2, 3])\n",
        "\n",
        "# 在 TensorFlow 2.x 中，不需要使用 session，可以直接运行\n",
        "targets = tf.one_hot(indices=labels, depth=5, on_value=1.0, off_value=0.0, axis=-1)\n",
        "print(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0afbfd2dac3d"
      },
      "source": [
        "这个问题通常是由于在使用自定义的损失函数时，将one-hot编码的标签张量（y_true）直接传递给损失函数而导致的。在这种情况下，直接对one-hot编码的张量进行操作可能会导致梯度消失，因为这些张量包含很多零值。为了避免这个问题，我们可以使用Tensorflow内置的函数来转换标签张量为稠密张量而不是one-hot编码的张量。\n",
        "\n",
        "以下是一个示例的解决方法，其中将使用SparseCategoricalCrossentropy作为示例损失函数：\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def my_loss(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) # 去掉size为1的维度\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "model.compile(optimizer='adam', loss=my_loss)\n",
        "在这个示例中，我们使用了Tensorflow的squeeze函数来去掉标签张量中size为1的维度，然后将其传递给SparseCategoricalCrossentropy函数。这将创建一个稠密的标签张量，从而避免了梯度消失的问题。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f44c0e155f79"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy()(y_true, y_pred)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mmy_loss)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def my_loss(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) # 去掉size为1的维度\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "model.compile(optimizer='adam', loss=my_loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "test_labelencoder.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
